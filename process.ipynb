{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective of the project üöÄ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My objective is to create a machine learning model for object classification and then, try and compare it with a convolutional neural network (CNN) for images. For that, I will use Spark MLlib to train and evaluate the model. Secondly, create the CNN and compare both ü™ê\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source of the data is: https://skyserver.sdss.org/CasJobs/\n",
    "It is necessary to register and login a user to download the data you want. Then, you have to make a query specifying:\n",
    "- Amount of rows\n",
    "- Columns\n",
    "- Where to keep the csv\n",
    "- The database\n",
    "\n",
    "As I want to get as much as possible data, I will not a maximum of rows.\n",
    "\n",
    "I also add a \"where\" so I can get only data from planets, galaxies and stars:\n",
    "- type = 3: Galaxies\n",
    "- type = 6: Stars\n",
    "\n",
    "and I downloaded the dataset to start working with it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/home/haizeagonzalez/myproject/bigDataAstronomy/notebookImages/img1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns we have are:\n",
    "- objID: Unique identifier of the object ‚Üí TYPE bigInt\n",
    "- ra: Right ascension ‚Üí TYPE float\n",
    "- dec: Declination ‚Üí TYPE float\n",
    "- petroRad: Petrosian radius, used to know the size of galaxies in astronomical pictures. It is the amount of light that a galaxy emits in a sepecific radius. Very used because it is independent of the distance and brightness. We use different photometric filters:\n",
    "    - petroRad_u: Near-ultraviolet\n",
    "    - petroRad_g: Blue-Green\n",
    "    - petroRad_r: Red\n",
    "    - petroRad_i: Near-infrared\n",
    "    - petroRad_z: Deeper infrared\n",
    " ‚Üí TYPE: Real\n",
    "\n",
    "- modelMag: Brightness measure adjusted to a galaxy model. Usual for galaxies. Also for all filters (u, g, r, i and z) ‚Üí TYPE Real\n",
    "- psfMag: Brightness measure based on the point source light profile. Usual for stars. Also for all filters (u, g, r, i and z) ‚Üí TYPE Real\n",
    "- u_g: (modelMag_u - modelMag_g)\n",
    "- g_r: (modelMag_g - modelMag_r)\n",
    "- r_i: (modelMag_r - modelMag_i)\n",
    "- i_z: (modelMag_i - modelMag_z)\n",
    "- fracDeV: The amount of brightness that the object has in the De Vaucouleurs profile. Also for all filters (u, g, r, i and z) ‚Üí TYPE Real\n",
    "- flags: Bit comination that explains different characteristics of the object. If we convert it to binary and check SDSS documentarion, we get a meaning for each bit ‚Üí TYPE bigInt\n",
    "- clean: Indicator that tell us if the object was cleaned ‚Üí TYPE int\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PetroRad:\n",
    "- Stars: Small and constant in all filters.\n",
    "- Galaxies: Bigger and variates depending on the wavelengths.\n",
    "\n",
    "ModelMag and psfMag:\n",
    "- In the red filter:\n",
    "    - Stars: modelMag_r ‚âà psfMag_r\n",
    "    - Galaxies: modelMag_r > psfMag_r\n",
    "- In other filers:\n",
    "    - Galaxies are usuarlly more red  (modelMag_g - modelMag_r is big).\n",
    "    - Stars has different colors depending on their type.\n",
    "\n",
    "fracDeV:\n",
    "- Stars: fracDeV ‚âà 0.\n",
    "- Galaxies: fracDeV ‚âà 1 (eliptic) or fracDeV < 1 (espiral).\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a spark sesion in case there is no one or get if there exists: \"getOrCreate\". I also decided to create a log in case there is any error during the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/03/14 12:49:29 WARN Utils: Your hostname, SSMRS3-04899600 resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/03/14 12:49:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/14 12:49:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"bigDataAstronomyProject\").getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to read de csv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/haizeagonzalez/bigDataProject/primaryObjs.csv\"\n",
    "path2 = \"/home/haizeagonzalez/myproject/primaryObjs_reduced.csv\"\n",
    "\n",
    "df = spark.read.csv(path2, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to check if the data is correctly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+----------------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-------------+----------+---------+---------+----------+----------+---------+-----------------+-----+\n",
      "|              objID|              ra|             dec|type|petroRad_u|petroRad_g|petroRad_r|petroRad_i|petroRad_z|modelMag_u|modelMag_g|modelMag_r|modelMag_i|modelMag_z|psfMag_u|psfMag_g|psfMag_r|psfMag_i|psfMag_z|      u_g|        g_r|          r_i|       i_z|fracDeV_u|fracDeV_g| fracDeV_r| fracDeV_i|fracDeV_z|            flags|clean|\n",
      "+-------------------+----------------+----------------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-------------+----------+---------+---------+----------+----------+---------+-----------------+-----+\n",
      "|1237645879562928227|15.9845663324886|1.26152915060923|   6|  2.292105|  1.707611|   1.64852|  1.665384|   1.72895|  21.24142|  18.88045|  17.57188|   16.3516|  15.70342|21.18578|18.87796|17.58161|16.35225|15.70951| 2.360977|   1.308565|     1.220278|  0.648181|        0|        0|         1|         0|        0|72057663025840640|    1|\n",
      "|1237645879562928257|16.0201215135359|1.26704396013378|   6|  1.416645|  1.706585|  1.806063|  1.698871|   1.59002|  20.94047|  19.81245|  19.50775|  19.46708|  19.44428|20.92997|19.81357|19.52817|19.49417|19.45141| 1.128021|  0.3046932|    0.0406723|0.02280426|        0|        0|         1| 0.9682192|        0|  105622104309776|    1|\n",
      "|1237645879562928258|16.0202444868512|1.26766725996923|   3|    1.7877|  2.502137|  2.517498|  2.491137|  2.925214|  20.96947|  20.29136|  19.36779|  18.86387|  18.45551|21.31432|20.77496|19.89376|19.36267|18.94779|0.6781197|  0.9235611|    0.5039272| 0.4083557|        1|0.5367593| 0.6309956|  0.483995|0.4169701|  123214290354192|    1|\n",
      "|1237645879562928288| 16.039249541437|1.27354455966896|   6|  3.081192|  1.571111|  1.639799|  1.751976|  1.643803|  22.72202|  20.31895|  19.05381|  18.48864|  18.24012|22.63377| 20.3004|19.04651|18.49125| 18.2252| 2.403069|   1.265142|    0.5651665| 0.2485256|        1|        1|         1|         1|        0|  105624251662352|    1|\n",
      "|1237645879562928320| 15.975197700978|1.26746375015348|   3|  2.630181|  2.494045|  2.282444|  2.831534|  3.743337|  20.85009|  20.68893|  20.23035|  20.25998|  19.87653|21.33208|21.15064|20.72256|20.72258|20.25971|0.1611595|  0.4585781|  -0.02962685| 0.3834496|        0|        0|         0| 0.7179593|        1|   17661174088192|    1|\n",
      "|1237645879562928327|15.9905813084437|1.27269073983438|   6|   1.40331|  2.054616|  1.545752|  1.798902|  3.136332|  21.73983|  20.72811|  20.50264|  20.24227|  20.60027|21.71885|20.73743|20.50063|20.23671|20.56597| 1.011717|  0.2254677|    0.2603779|-0.3580036|        1|        1|         0|         0|        1|      68987912192|    1|\n",
      "|1237645879562928336|16.0157223345984|1.25963078310394|   3|  2.979839|  2.274302|  1.671784|  2.529637|  18.01689|  21.84128|  21.01279|  21.07722|  20.66992|  21.74303| 21.8785|21.15424|21.27471|20.84274|22.06019|0.8284893|-0.06442833|     0.407299| -1.073112|        1|        1|         0|         0|        0|      68987912448|    1|\n",
      "|1237645879562928380|15.9512563612708|1.27267371672791|   3|  2.674224|  6.080884|  3.453848|  2.989547|  3.858347|  22.10587|  20.14287|  18.95277|  18.47308|  18.13216|22.84973|20.90354|19.75539|19.24854|18.87341| 1.963003|   1.190102|    0.4796886| 0.3409176|0.6466128|        1|         1|         1|        1|      68987912704|    1|\n",
      "|1237645879562928447|15.9681325711342|1.26377361987617|   3|0.07362713|  3.238121|  2.635657|  2.960654|  3.935807|  22.81256|  21.11735|  19.96747|  19.48209|   19.1643| 23.0449|21.68723|20.60173|20.09334|19.73695| 1.695217|   1.149879|    0.4853783| 0.3177891|        1|        1|         0|0.03121131|        1|     217164283904|    1|\n",
      "|1237645879562928458|15.9746356676525|1.27037341592381|   3|  2.968999|  3.981241|  3.510127|   5.13227|  2.564884|   22.7284|  21.11578|  19.98799|  19.47666|  19.31503|24.07744|22.14063|20.91185|20.29441|19.85671| 1.612616|    1.12779|    0.5113297| 0.1616306|        0|        0| 0.2283276|         1|0.0746816|      68987912448|    1|\n",
      "|1237645879562928468|15.9782109215193|1.26161669596641|   6|  1.574493|  1.575985|  1.595708|  1.473315|  1.579862|  23.04424|  21.37888|  20.79089|  20.79133|  20.23663|23.04468| 21.3451|20.77657|20.76188|20.25072| 1.665363|  0.5879917|-0.0004463196| 0.5546989|        1|        0|         0|         0|        0|     217164283904|    1|\n",
      "|1237645879562928474|15.9811431563106|1.26539397998321|   3|   1.09723|  2.163676|  2.224645|  2.378153|  2.575627|  22.41774|  20.96367|   19.8374|   19.3973|  19.07894|22.64011|21.37158|20.28062|19.80586|19.43799| 1.454069|   1.126266|    0.4401054| 0.3183575|        1|0.3387169| 0.8607913|  0.958482|0.8836669|      68987912192|    1|\n",
      "|1237645879562928475|15.9812942740556|1.27059628503902|   3|  1.894444|  2.424407|  2.203035|  2.106368|0.08154033|  22.53058|   21.4278|  21.01363|  20.73903|  20.64127|22.81935|21.73014|21.29692| 21.0396| 21.1542| 1.102772|  0.4141731|    0.2745991|0.09776497|        0|0.5419235|         1|         0|        0|      68988043264|    1|\n",
      "|1237645879562928479|15.9849255490641|1.27361851881959|   3|  4.582631|  3.038905|  2.393418|  2.472933|  3.138511|  22.31236|  20.96439|  20.09109|  19.66039|  19.25382|22.86162|21.50844|20.68131|20.19696|19.82464| 1.347969|  0.8733006|    0.4307022| 0.4065742|        1|0.2974474|         0|         0|        0|      68987912448|    1|\n",
      "|1237645879562928482|15.9857528380243|1.26419278236687|   3| 0.6941419|  2.390916|  1.946412|  3.141908|   7.35819|  23.40549|  21.48515|  20.26601|   19.6862|  19.26554|23.58897|21.71788| 20.5232|19.96947|19.55517| 1.920341|   1.219145|    0.5798035| 0.4206638|        1|        1|         1|         1|        1|   35253360132880|    1|\n",
      "|1237645879562928483|15.9856705715358|1.26495487691343|   3|  2.968999|  2.968706|   3.12309|  1.793412|  1.105405|  23.75709|  21.20225|  20.43233|  20.58068|  20.36777|23.89693|21.81693|21.12529|21.12756|20.83029|  2.55484|  0.7699242|   -0.1483459| 0.2129097|        1|0.8018683| 0.7939583| 0.2807959|0.8632594|  105624251794192|    1|\n",
      "|1237645879562928496|15.9903760476136|1.26790158857995|   3|  11.30261|  2.750925|  2.468824|  2.487736|  3.155129|  22.56447|  20.72183|  19.61603|  19.15697|  18.80848|23.03562|21.29687|20.19573|19.69263|19.26701| 1.842638|   1.105804|    0.4590511| 0.3484974|        0|        0| 0.3161026| 0.1698431|0.9868296|      68987912448|    1|\n",
      "|1237645879562928514|15.9965191833479|1.27202324310138|   3|  2.587464|  3.065605|  2.870225|  2.912822|  3.119462|  22.16124|  21.11859|  20.59915|   20.3402|   20.2723|22.86283|21.86053|21.29682|21.11195|20.90944| 1.042652|  0.5194397|    0.2589512|0.06789589|        0|        0|0.03981618|         0|        0|      68987912192|    1|\n",
      "|1237645879562928537|16.0031746141793|1.26704313651337|   3|  2.968999|  2.968706|  2.274027|  1.853262|  1.130265|  22.77491|  22.45722|  21.85404|  21.85186|  20.76013|22.85994|22.73065|22.14377|22.19438| 21.0263| 0.317688|  0.6031818|  0.002176285|  1.091728|        1|        1|         0|         0|        0|  422281453109504|    1|\n",
      "|1237645879562928544|16.0066031635466|1.26929886051142|   3|  2.968999|  2.968706|  2.439569|   2.96943| 0.2905966|  24.19897|  22.53636|  21.81102|  22.58995|  22.78549|24.40637|22.87906|22.14854|23.18853|22.65568| 1.662605|  0.7253418|   -0.7789326|-0.1955338|        0|        0|         1|         0|        1|  281543964623104|    1|\n",
      "+-------------------+----------------+----------------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-------------+----------+---------+---------+----------+----------+---------+-----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema and the chacacteristics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- objID: string (nullable = true)\n",
      " |-- ra: string (nullable = true)\n",
      " |-- dec: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- petroRad_u: string (nullable = true)\n",
      " |-- petroRad_g: string (nullable = true)\n",
      " |-- petroRad_r: string (nullable = true)\n",
      " |-- petroRad_i: string (nullable = true)\n",
      " |-- petroRad_z: string (nullable = true)\n",
      " |-- modelMag_u: string (nullable = true)\n",
      " |-- modelMag_g: string (nullable = true)\n",
      " |-- modelMag_r: string (nullable = true)\n",
      " |-- modelMag_i: string (nullable = true)\n",
      " |-- modelMag_z: string (nullable = true)\n",
      " |-- psfMag_u: string (nullable = true)\n",
      " |-- psfMag_g: string (nullable = true)\n",
      " |-- psfMag_r: string (nullable = true)\n",
      " |-- psfMag_i: string (nullable = true)\n",
      " |-- psfMag_z: string (nullable = true)\n",
      " |-- u_g: string (nullable = true)\n",
      " |-- g_r: string (nullable = true)\n",
      " |-- r_i: string (nullable = true)\n",
      " |-- i_z: string (nullable = true)\n",
      " |-- fracDeV_u: string (nullable = true)\n",
      " |-- fracDeV_g: string (nullable = true)\n",
      " |-- fracDeV_r: string (nullable = true)\n",
      " |-- fracDeV_i: string (nullable = true)\n",
      " |-- fracDeV_z: string (nullable = true)\n",
      " |-- flags: string (nullable = true)\n",
      " |-- clean: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all columns are string, we need to convert them into their type. For that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- objID: long (nullable = true)\n",
      " |-- ra: float (nullable = true)\n",
      " |-- dec: float (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- petroRad_u: float (nullable = true)\n",
      " |-- petroRad_g: float (nullable = true)\n",
      " |-- petroRad_r: float (nullable = true)\n",
      " |-- petroRad_i: float (nullable = true)\n",
      " |-- petroRad_z: float (nullable = true)\n",
      " |-- modelMag_u: float (nullable = true)\n",
      " |-- modelMag_g: float (nullable = true)\n",
      " |-- modelMag_r: float (nullable = true)\n",
      " |-- modelMag_i: float (nullable = true)\n",
      " |-- modelMag_z: float (nullable = true)\n",
      " |-- psfMag_u: float (nullable = true)\n",
      " |-- psfMag_g: float (nullable = true)\n",
      " |-- psfMag_r: float (nullable = true)\n",
      " |-- psfMag_i: float (nullable = true)\n",
      " |-- psfMag_z: float (nullable = true)\n",
      " |-- u_g: float (nullable = true)\n",
      " |-- g_r: float (nullable = true)\n",
      " |-- r_i: float (nullable = true)\n",
      " |-- i_z: float (nullable = true)\n",
      " |-- fracDeV_u: float (nullable = true)\n",
      " |-- fracDeV_g: float (nullable = true)\n",
      " |-- fracDeV_r: float (nullable = true)\n",
      " |-- fracDeV_i: float (nullable = true)\n",
      " |-- fracDeV_z: float (nullable = true)\n",
      " |-- flags: long (nullable = true)\n",
      " |-- clean: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"objID\", col(\"objID\").cast(\"long\")) \\\n",
    "       .withColumn(\"ra\", col(\"ra\").cast(\"float\")) \\\n",
    "       .withColumn(\"dec\", col(\"dec\").cast(\"float\")) \\\n",
    "       .withColumn(\"petroRad_u\", col(\"petroRad_u\").cast(\"float\")) \\\n",
    "       .withColumn(\"petroRad_g\", col(\"petroRad_g\").cast(\"float\")) \\\n",
    "       .withColumn(\"petroRad_r\", col(\"petroRad_r\").cast(\"float\")) \\\n",
    "       .withColumn(\"petroRad_i\", col(\"petroRad_i\").cast(\"float\")) \\\n",
    "       .withColumn(\"petroRad_z\", col(\"petroRad_z\").cast(\"float\")) \\\n",
    "       .withColumn(\"modelMag_u\", col(\"modelMag_u\").cast(\"float\")) \\\n",
    "       .withColumn(\"modelMag_g\", col(\"modelMag_g\").cast(\"float\")) \\\n",
    "       .withColumn(\"modelMag_r\", col(\"modelMag_r\").cast(\"float\")) \\\n",
    "       .withColumn(\"modelMag_i\", col(\"modelMag_i\").cast(\"float\")) \\\n",
    "       .withColumn(\"modelMag_z\", col(\"modelMag_z\").cast(\"float\")) \\\n",
    "       .withColumn(\"psfMag_u\", col(\"psfMag_u\").cast(\"float\")) \\\n",
    "       .withColumn(\"psfMag_g\", col(\"psfMag_g\").cast(\"float\")) \\\n",
    "       .withColumn(\"psfMag_r\", col(\"psfMag_r\").cast(\"float\")) \\\n",
    "       .withColumn(\"psfMag_i\", col(\"psfMag_i\").cast(\"float\")) \\\n",
    "       .withColumn(\"psfMag_z\", col(\"psfMag_z\").cast(\"float\")) \\\n",
    "       .withColumn(\"u_g\", col(\"u_g\").cast(\"float\")) \\\n",
    "       .withColumn(\"g_r\", col(\"g_r\").cast(\"float\")) \\\n",
    "       .withColumn(\"r_i\", col(\"r_i\").cast(\"float\")) \\\n",
    "       .withColumn(\"i_z\", col(\"i_z\").cast(\"float\")) \\\n",
    "       .withColumn(\"fracDeV_u\", col(\"fracDeV_u\").cast(\"float\")) \\\n",
    "       .withColumn(\"fracDeV_g\", col(\"fracDeV_g\").cast(\"float\")) \\\n",
    "       .withColumn(\"fracDeV_r\", col(\"fracDeV_r\").cast(\"float\")) \\\n",
    "       .withColumn(\"fracDeV_i\", col(\"fracDeV_i\").cast(\"float\")) \\\n",
    "       .withColumn(\"fracDeV_z\", col(\"fracDeV_z\").cast(\"float\")) \\\n",
    "       .withColumn(\"flags\", col(\"flags\").cast(\"long\")) \\\n",
    "       .withColumn(\"clean\", col(\"clean\").cast(\"int\"))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the structure, we are going to explore and clean the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the data is cleaned because we get it from CasJobs and we apply clear filter to get good data. However, we are going to check whether there is any null value and the amount of galaxies and stars.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---+---+---+---+---------+---------+---------+---------+---------+-----+-----+\n",
      "|objID| ra|dec|type|petroRad_u|petroRad_g|petroRad_r|petroRad_i|petroRad_z|modelMag_u|modelMag_g|modelMag_r|modelMag_i|modelMag_z|psfMag_u|psfMag_g|psfMag_r|psfMag_i|psfMag_z|u_g|g_r|r_i|i_z|fracDeV_u|fracDeV_g|fracDeV_r|fracDeV_i|fracDeV_z|flags|clean|\n",
      "+-----+---+---+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---+---+---+---+---------+---------+---------+---------+---------+-----+-----+\n",
      "|    0|  0|  0|   0|         0|         0|         0|         0|         0|         0|         0|         0|         0|         0|       0|       0|       0|       0|       0|  0|  0|  0|  0|        0|        0|        0|        0|        0|    0|    0|\n",
      "+-----+---+---+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---+---+---+---+---------+---------+---------+---------+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|type|count|\n",
      "+----+-----+\n",
      "|   3|53538|\n",
      "|   6|46462|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"type\").count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is no null values and the amount of galaxies are less than the amount of stars, which make sense. However, this can affect the model so we are going to balance the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as it is a binary classification, we will update stars to 0 and galaxies to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"type\", when(col(\"type\") == 6,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "|              objID|       ra|      dec|type|petroRad_u|petroRad_g|petroRad_r|petroRad_i|petroRad_z|modelMag_u|modelMag_g|modelMag_r|modelMag_i|modelMag_z|psfMag_u|psfMag_g|psfMag_r|psfMag_i|psfMag_z|      u_g|        g_r|        r_i|      i_z|fracDeV_u|fracDeV_g|fracDeV_r| fracDeV_i|fracDeV_z|          flags|clean|\n",
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "|1237645879562928258|16.020245|1.2676673|   0|    1.7877|  2.502137|  2.517498|  2.491137|  2.925214|  20.96947|  20.29136|  19.36779|  18.86387|  18.45551|21.31432|20.77496|19.89376|19.36267|18.94779|0.6781197|  0.9235611|  0.5039272|0.4083557|      1.0|0.5367593|0.6309956|  0.483995|0.4169701|123214290354192|    1|\n",
      "|1237645879562928320|15.975198|1.2674638|   0|  2.630181|  2.494045|  2.282444|  2.831534|  3.743337|  20.85009|  20.68893|  20.23035|  20.25998|  19.87653|21.33208|21.15064|20.72256|20.72258|20.25971|0.1611595|  0.4585781|-0.02962685|0.3834496|      0.0|      0.0|      0.0| 0.7179593|      1.0| 17661174088192|    1|\n",
      "|1237645879562928336|16.015722|1.2596308|   0|  2.979839|  2.274302|  1.671784|  2.529637|  18.01689|  21.84128|  21.01279|  21.07722|  20.66992|  21.74303| 21.8785|21.15424|21.27471|20.84274|22.06019|0.8284893|-0.06442833|   0.407299|-1.073112|      1.0|      1.0|      0.0|       0.0|      0.0|    68987912448|    1|\n",
      "|1237645879562928380|15.951257|1.2726737|   0|  2.674224|  6.080884|  3.453848|  2.989547|  3.858347|  22.10587|  20.14287|  18.95277|  18.47308|  18.13216|22.84973|20.90354|19.75539|19.24854|18.87341| 1.963003|   1.190102|  0.4796886|0.3409176|0.6466128|      1.0|      1.0|       1.0|      1.0|    68987912704|    1|\n",
      "|1237645879562928447|15.968133|1.2637736|   0|0.07362713|  3.238121|  2.635657|  2.960654|  3.935807|  22.81256|  21.11735|  19.96747|  19.48209|   19.1643| 23.0449|21.68723|20.60173|20.09334|19.73695| 1.695217|   1.149879|  0.4853783|0.3177891|      1.0|      1.0|      0.0|0.03121131|      1.0|   217164283904|    1|\n",
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+----------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+--------+---------+------------+----------+---------+---------+---------+---------+---------+-----------------+-----+\n",
      "|              objID|        ra|      dec|type|petroRad_u|petroRad_g|petroRad_r|petroRad_i|petroRad_z|modelMag_u|modelMag_g|modelMag_r|modelMag_i|modelMag_z|psfMag_u|psfMag_g|psfMag_r|psfMag_i|psfMag_z|     u_g|      g_r|         r_i|       i_z|fracDeV_u|fracDeV_g|fracDeV_r|fracDeV_i|fracDeV_z|            flags|clean|\n",
      "+-------------------+----------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+--------+---------+------------+----------+---------+---------+---------+---------+---------+-----------------+-----+\n",
      "|1237645879562928227| 15.984567|1.2615292|   1|  2.292105|  1.707611|   1.64852|  1.665384|   1.72895|  21.24142|  18.88045|  17.57188|   16.3516|  15.70342|21.18578|18.87796|17.58161|16.35225|15.70951|2.360977| 1.308565|    1.220278|  0.648181|      0.0|      0.0|      1.0|      0.0|      0.0|72057663025840640|    1|\n",
      "|1237645879562928257|  16.02012| 1.267044|   1|  1.416645|  1.706585|  1.806063|  1.698871|   1.59002|  20.94047|  19.81245|  19.50775|  19.46708|  19.44428|20.92997|19.81357|19.52817|19.49417|19.45141|1.128021|0.3046932|   0.0406723|0.02280426|      0.0|      0.0|      1.0|0.9682192|      0.0|  105622104309776|    1|\n",
      "|1237645879562928288|  16.03925|1.2735445|   1|  3.081192|  1.571111|  1.639799|  1.751976|  1.643803|  22.72202|  20.31895|  19.05381|  18.48864|  18.24012|22.63377| 20.3004|19.04651|18.49125| 18.2252|2.403069| 1.265142|   0.5651665| 0.2485256|      1.0|      1.0|      1.0|      1.0|      0.0|  105624251662352|    1|\n",
      "|1237645879562928327|15.9905815|1.2726908|   1|   1.40331|  2.054616|  1.545752|  1.798902|  3.136332|  21.73983|  20.72811|  20.50264|  20.24227|  20.60027|21.71885|20.73743|20.50063|20.23671|20.56597|1.011717|0.2254677|   0.2603779|-0.3580036|      1.0|      1.0|      0.0|      0.0|      1.0|      68987912192|    1|\n",
      "|1237645879562928468|  15.97821|1.2616167|   1|  1.574493|  1.575985|  1.595708|  1.473315|  1.579862|  23.04424|  21.37888|  20.79089|  20.79133|  20.23663|23.04468| 21.3451|20.77657|20.76188|20.25072|1.665363|0.5879917|-4.463196E-4| 0.5546989|      1.0|      0.0|      0.0|      0.0|      0.0|     217164283904|    1|\n",
      "+-------------------+----------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+--------+---------+------------+----------+---------+---------+---------+---------+---------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_stars = df.filter(df[\"type\"] == 0)\n",
    "df_galaxies = df.filter(df[\"type\"] == 1)\n",
    "\n",
    "#Print to know the conversion is correctly done\n",
    "df_stars.show(5)\n",
    "df_galaxies.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we are going to balance the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|type|count|\n",
      "+----+-----+\n",
      "|   0|46507|\n",
      "|   1|46462|\n",
      "+----+-----+\n",
      "\n",
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "|              objID|       ra|      dec|type|petroRad_u|petroRad_g|petroRad_r|petroRad_i|petroRad_z|modelMag_u|modelMag_g|modelMag_r|modelMag_i|modelMag_z|psfMag_u|psfMag_g|psfMag_r|psfMag_i|psfMag_z|      u_g|        g_r|        r_i|      i_z|fracDeV_u|fracDeV_g|fracDeV_r| fracDeV_i|fracDeV_z|          flags|clean|\n",
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "|1237645879562928258|16.020245|1.2676673|   0|    1.7877|  2.502137|  2.517498|  2.491137|  2.925214|  20.96947|  20.29136|  19.36779|  18.86387|  18.45551|21.31432|20.77496|19.89376|19.36267|18.94779|0.6781197|  0.9235611|  0.5039272|0.4083557|      1.0|0.5367593|0.6309956|  0.483995|0.4169701|123214290354192|    1|\n",
      "|1237645879562928320|15.975198|1.2674638|   0|  2.630181|  2.494045|  2.282444|  2.831534|  3.743337|  20.85009|  20.68893|  20.23035|  20.25998|  19.87653|21.33208|21.15064|20.72256|20.72258|20.25971|0.1611595|  0.4585781|-0.02962685|0.3834496|      0.0|      0.0|      0.0| 0.7179593|      1.0| 17661174088192|    1|\n",
      "|1237645879562928336|16.015722|1.2596308|   0|  2.979839|  2.274302|  1.671784|  2.529637|  18.01689|  21.84128|  21.01279|  21.07722|  20.66992|  21.74303| 21.8785|21.15424|21.27471|20.84274|22.06019|0.8284893|-0.06442833|   0.407299|-1.073112|      1.0|      1.0|      0.0|       0.0|      0.0|    68987912448|    1|\n",
      "|1237645879562928380|15.951257|1.2726737|   0|  2.674224|  6.080884|  3.453848|  2.989547|  3.858347|  22.10587|  20.14287|  18.95277|  18.47308|  18.13216|22.84973|20.90354|19.75539|19.24854|18.87341| 1.963003|   1.190102|  0.4796886|0.3409176|0.6466128|      1.0|      1.0|       1.0|      1.0|    68987912704|    1|\n",
      "|1237645879562928447|15.968133|1.2637736|   0|0.07362713|  3.238121|  2.635657|  2.960654|  3.935807|  22.81256|  21.11735|  19.96747|  19.48209|   19.1643| 23.0449|21.68723|20.60173|20.09334|19.73695| 1.695217|   1.149879|  0.4853783|0.3177891|      1.0|      1.0|      0.0|0.03121131|      1.0|   217164283904|    1|\n",
      "+-------------------+---------+---------+----+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+--------+--------+--------+--------+--------+---------+-----------+-----------+---------+---------+---------+---------+----------+---------+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Get the amount of stars and galaxies\n",
    "count_stars = df.filter(col(\"type\") == 0).count()\n",
    "count_galaxies = df.filter(col(\"type\") == 1).count()\n",
    "\n",
    "#Select the minimum number of both clases\n",
    "min_count = min(count_stars, count_galaxies)\n",
    "\n",
    "# Submuestreo: Tomar solo 'min_count' elementos de cada clase\n",
    "df_stars = df.filter(col(\"type\") == 0).sample(fraction=min_count / count_stars, seed=1)\n",
    "df_galaxies = df.filter(col(\"type\") == 1).sample(fraction=min_count / count_galaxies, seed=1)\n",
    "\n",
    "#Union the data\n",
    "df_balanced = df_stars.union(df_galaxies)\n",
    "\n",
    "#Check if everything is ok\n",
    "df_balanced.groupBy(\"type\").count().show()\n",
    "df_balanced.show(5)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't get exactly the same amount of data beacuse PySpark approximates the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the supervised machine model we won't use objID, ra, dec, flags and clean columns, we are going to remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- type: integer (nullable = false)\n",
      " |-- petroRad_u: float (nullable = true)\n",
      " |-- petroRad_g: float (nullable = true)\n",
      " |-- petroRad_r: float (nullable = true)\n",
      " |-- petroRad_i: float (nullable = true)\n",
      " |-- petroRad_z: float (nullable = true)\n",
      " |-- modelMag_u: float (nullable = true)\n",
      " |-- modelMag_g: float (nullable = true)\n",
      " |-- modelMag_r: float (nullable = true)\n",
      " |-- modelMag_i: float (nullable = true)\n",
      " |-- modelMag_z: float (nullable = true)\n",
      " |-- psfMag_u: float (nullable = true)\n",
      " |-- psfMag_g: float (nullable = true)\n",
      " |-- psfMag_r: float (nullable = true)\n",
      " |-- psfMag_i: float (nullable = true)\n",
      " |-- psfMag_z: float (nullable = true)\n",
      " |-- u_g: float (nullable = true)\n",
      " |-- g_r: float (nullable = true)\n",
      " |-- r_i: float (nullable = true)\n",
      " |-- i_z: float (nullable = true)\n",
      " |-- fracDeV_u: float (nullable = true)\n",
      " |-- fracDeV_g: float (nullable = true)\n",
      " |-- fracDeV_r: float (nullable = true)\n",
      " |-- fracDeV_i: float (nullable = true)\n",
      " |-- fracDeV_z: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ml_model = df_balanced.select(\"type\", \"petroRad_u\", \"petroRad_g\", \"petroRad_r\", \"petroRad_i\", \"petroRad_z\",\n",
    "                        \"modelMag_u\", \"modelMag_g\", \"modelMag_r\", \"modelMag_i\", \"modelMag_z\",\n",
    "                        \"psfMag_u\", \"psfMag_g\", \"psfMag_r\", \"psfMag_i\", \"psfMag_z\",\n",
    "                        \"u_g\", \"g_r\", \"r_i\", \"i_z\",\n",
    "                        \"fracDeV_u\", \"fracDeV_g\", \"fracDeV_r\", \"fracDeV_i\", \"fracDeV_z\")\n",
    "\n",
    "df_ml_model.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our objective is to create a machine learning model, we need to convert the data in a correct format: Vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = df.columns[1:] #We don't get the type beacuse is the result we want to get.\n",
    "assembler = VectorAssembler(inputCols = features, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|Type|\n",
      "+--------------------+----+\n",
      "|[15.9845666885375...|   1|\n",
      "|[16.0201206207275...|   1|\n",
      "|[16.0202445983886...|   0|\n",
      "|[16.0392494201660...|   1|\n",
      "|[15.9751977920532...|   0|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = assembler.transform(df).select(\"features\", \"Type\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to divide the dataset into train and test, so we can get the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try different models to check which is the best for our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LinearSVC\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(labelCol = \"Type\", featuresCol = \"features\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"Type\", featuresCol=\"features\"),\n",
    "    #\"Random Forest\": RandomForestClassifier(labelCol=\"Type\", featuresCol=\"features\", numTrees=100),\n",
    "    #\"Gradient Boosted Trees\": GBTClassifier(labelCol=\"Type\", featuresCol=\"features\"),\n",
    "    #\"Linear SVM\": LinearSVC(labelCol=\"Type\", featuresCol=\"features\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol = \"Type\", metricName = \"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Type\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 1.0000\n",
      "Decision Tree: Accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model_trained = model.fit(train_data)\n",
    "    predictions = model_trained.transform(test_data)\n",
    "    #auc = evaluator.evaluate(predictions)\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    #print(f\"{name}: AUC = {auc:.4f}\")\n",
    "    print(f\"{name}: Accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haizeagonzalez/myproject/bigdataenv/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Confusion Matrix\n",
      "[[10563.     0.]\n",
      " [    0.  9195.]]\n",
      "Decision Tree: Accuracy = 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haizeagonzalez/myproject/bigdataenv/lib/python3.12/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: Confusion Matrix\n",
      "[[10563.     0.]\n",
      " [    0.  9195.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Entrenamiento del modelo\n",
    "    model_trained = model.fit(train_data)\n",
    "\n",
    "    # Predicciones\n",
    "    predictions = model_trained.transform(test_data)\n",
    "    \n",
    "    # Evaluaci√≥n\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(f\"{name}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # Seleccionar las columnas de predicci√≥n y etiquetas\n",
    "    predictionAndLabels = predictions.select(\n",
    "        F.col(\"prediction\").cast(FloatType()), \n",
    "        F.col(\"type\").cast(FloatType())  # Asegurarse de que 'type' es float\n",
    "    )\n",
    "\n",
    "    # Convertir a RDD para usar MulticlassMetrics\n",
    "    metrics = MulticlassMetrics(predictionAndLabels.rdd.map(tuple))\n",
    "\n",
    "    # Obtener la matriz de confusi√≥n\n",
    "    conf_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    # Mostrar la matriz de confusi√≥n\n",
    "    print(f\"{name}: Confusion Matrix\")\n",
    "    print(conf_matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation\n",
    "\n",
    "matriz confusion -> Si esta bien (cross validation si esta mal overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El accuracy el 100 pero puede ser que haya sido overfitting por tanto, puede ser que al haber m√°s estrellas que galaxias, prediga el que m√°s haya. Es por ello que vamos a bajar la cantidad de estrellas para que el modelo est√© balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46507\n",
      "46462\n"
     ]
    }
   ],
   "source": [
    "print(df_stars.count())\n",
    "print(df_galaxies.count())\n",
    "\n",
    "num_stars = df_stars.count()\n",
    "num_galaxies = df_galaxies.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I need also de images, I have downloaded from https://skyserver.sdss.org/dr18, specifying with a request:\n",
    "- the location of the object (with right ascension (RA) and declination (dec))\n",
    "- the zoom of the picture (scale)\n",
    "- the dimmensions of the photo (with and height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdataenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
